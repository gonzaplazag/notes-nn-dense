{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de clasificación de imagenes con TF\n",
    "# Se introduce el dataset fashion-mnist como dataset de trabajo.\n",
    "# Se introducen las redes densas (Dense, Full Connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.17.0\n",
      "numpy version: 1.26.4\n",
      "keras version: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(f'tensorflow version: {tf.__version__}')\n",
    "print(f'numpy version: {np.__version__}')\n",
    "print(f'keras version: {keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Load\n",
    "# --------------------------------\n",
    "\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60k imagenes de 28x28 pixeles\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 79\n",
      "Label: 9\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00392157 0.00392157\n",
      "  0.00784314 0.         0.         0.         0.         0.13333333\n",
      "  0.10980392 0.         0.01568627 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.00784314 0.         0.01960784\n",
      "  0.04313725 0.00784314 0.01176471 0.         0.         0.\n",
      "  0.         0.         0.         0.13333333 0.56078431 0.9372549\n",
      "  0.69803922 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17254902 0.56862745 0.91372549 0.93333333 0.96470588 0.89803922\n",
      "  0.86666667 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00784314 0.         0.3254902\n",
      "  0.52156863 0.54901961 0.59215686 0.67843137 0.87843137 1.\n",
      "  0.9372549  0.94509804 0.92941176 0.87843137 0.86666667 0.85490196\n",
      "  0.96470588 0.44313725 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.01568627 0.         0.65882353\n",
      "  0.94509804 0.90588235 0.9254902  0.92941176 0.90980392 0.88235294\n",
      "  0.86666667 0.8627451  0.8745098  0.89019608 0.89019608 0.87843137\n",
      "  0.87843137 0.97647059 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.7254902\n",
      "  0.84313725 0.82352941 0.83921569 0.81568627 0.84705882 0.87843137\n",
      "  0.89019608 0.89019608 0.89019608 0.88235294 0.87843137 0.88627451\n",
      "  0.8627451  0.95686275 0.40392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00784314 0.         0.05098039 0.80784314\n",
      "  0.85490196 0.84705882 0.8627451  0.85882353 0.87058824 0.87843137\n",
      "  0.88235294 0.88627451 0.88627451 0.89019608 0.90196078 0.89411765\n",
      "  0.87843137 0.89803922 0.95686275 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.02352941 0.         0.11764706 0.87058824\n",
      "  0.83137255 0.8745098  0.8627451  0.8627451  0.87058824 0.87843137\n",
      "  0.88235294 0.88627451 0.88627451 0.89019608 0.87843137 0.89803922\n",
      "  0.85882353 0.87843137 1.         0.23137255]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.         0.3254902  0.87843137\n",
      "  0.83529412 0.88235294 0.86666667 0.86666667 0.8745098  0.88235294\n",
      "  0.88235294 0.89019608 0.88627451 0.89019608 0.89411765 0.87843137\n",
      "  0.88235294 0.88235294 1.         0.55686275]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.57647059 0.87843137\n",
      "  0.83921569 0.88627451 0.88235294 0.87058824 0.8745098  0.88235294\n",
      "  0.88235294 0.87843137 0.88627451 0.89411765 0.89411765 0.89019608\n",
      "  0.89411765 0.88627451 0.9372549  0.76470588]\n",
      " [0.         0.         0.         0.         0.00392157 0.\n",
      "  0.         0.00392157 0.         0.         0.78431373 0.83921569\n",
      "  0.80392157 0.85490196 0.8745098  0.8745098  0.87058824 0.89019608\n",
      "  0.89019608 0.88627451 0.87843137 0.88235294 0.89019608 0.89019608\n",
      "  0.89803922 0.89803922 0.94117647 0.76862745]\n",
      " [0.         0.         0.         0.         0.         0.01176471\n",
      "  0.00392157 0.01176471 0.         0.01960784 0.96862745 0.78823529\n",
      "  0.78431373 0.83529412 0.85098039 0.88627451 0.88627451 0.88627451\n",
      "  0.88235294 0.89019608 0.88627451 0.87843137 0.83137255 0.83137255\n",
      "  0.86666667 0.88235294 1.         0.45098039]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.01568627 0.         0.32941176 0.85490196 0.81568627\n",
      "  0.86666667 0.84705882 0.84705882 0.89411765 0.89411765 0.8745098\n",
      "  0.87058824 0.89411765 0.87843137 0.85882353 1.         1.\n",
      "  0.92156863 0.85490196 1.         0.10196078]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00784314 0.         0.         0.72156863 0.79215686 0.81176471\n",
      "  0.87843137 0.83529412 0.81960784 0.8627451  0.89411765 0.88235294\n",
      "  0.89411765 0.85490196 0.91372549 1.         0.65882353 0.4\n",
      "  0.82745098 0.92941176 0.81176471 0.        ]\n",
      " [0.00392157 0.         0.         0.         0.01960784 0.01176471\n",
      "  0.01568627 0.         0.29019608 0.92941176 0.75686275 0.87843137\n",
      "  0.78823529 0.76862745 0.94117647 0.94117647 0.95686275 0.85098039\n",
      "  0.84705882 0.94117647 0.89411765 0.10980392 0.         0.\n",
      "  0.08235294 0.99215686 0.6745098  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12941176 0.91764706 0.82352941 0.79215686 0.85490196\n",
      "  0.88235294 0.87058824 0.89019608 0.74509804 0.69411765 0.88627451\n",
      "  0.94117647 0.73333333 0.         0.         0.         0.\n",
      "  0.03921569 0.98431373 0.54117647 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.40392157 0.9372549  0.83921569 0.74901961 0.80392157 0.87843137\n",
      "  0.8745098  0.89803922 0.83529412 0.83529412 0.74117647 0.94509804\n",
      "  0.59607843 0.         0.         0.00784314 0.00392157 0.\n",
      "  0.03529412 0.98039216 0.4        0.        ]\n",
      " [0.         0.01568627 0.         0.47843137 0.89411765 0.78039216\n",
      "  0.94901961 0.80784314 0.79607843 0.82745098 0.80784314 0.87843137\n",
      "  0.85098039 0.86666667 0.75686275 0.83137255 0.96862745 0.59215686\n",
      "  0.         0.         0.         0.         0.00392157 0.\n",
      "  0.00784314 0.96470588 0.29019608 0.        ]\n",
      " [0.         0.         0.         0.69411765 0.87058824 0.77254902\n",
      "  0.74509804 0.81960784 0.81568627 0.81960784 0.86666667 0.87058824\n",
      "  0.90588235 0.89019608 0.85882353 0.90980392 0.71372549 0.\n",
      "  0.         0.         0.         0.         0.01568627 0.\n",
      "  0.         0.91764706 0.25882353 0.        ]\n",
      " [0.         0.         0.04705882 0.78431373 0.79215686 0.8\n",
      "  0.83137255 0.80784314 0.82745098 0.87058824 0.86666667 0.89019608\n",
      "  0.88235294 0.85490196 0.90196078 0.89803922 0.         0.\n",
      "  0.         0.         0.         0.         0.01176471 0.\n",
      "  0.         0.85882353 0.14509804 0.        ]\n",
      " [0.30588235 0.85490196 0.77647059 0.81568627 0.80784314 0.81960784\n",
      "  0.80392157 0.82745098 0.85490196 0.87843137 0.89411765 0.88235294\n",
      "  0.85490196 0.86666667 0.88627451 0.11764706 0.         0.02745098\n",
      "  0.         0.         0.         0.         0.00784314 0.\n",
      "  0.         0.83529412 0.12941176 0.        ]\n",
      " [0.         0.51372549 0.83529412 0.9372549  0.91764706 0.88627451\n",
      "  0.85882353 0.83137255 0.83921569 0.80784314 0.83137255 0.83529412\n",
      "  0.89019608 0.91372549 0.33333333 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00392157 0.\n",
      "  0.         0.80392157 0.20784314 0.        ]\n",
      " [0.         0.         0.         0.38431373 0.69019608 0.88235294\n",
      "  1.         1.         1.         1.         0.91764706 0.92156863\n",
      "  0.98431373 0.30980392 0.         0.         0.         0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.81568627 0.17254902 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05098039 0.2        0.25882353 0.29019608 0.29411765 0.24705882\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40392157 0.03529412 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# Show\n",
    "# --------------------------------\n",
    "INDEX = np.random.randint(100)\n",
    "\n",
    "# 0 T-shirt/top\n",
    "# 1 Trouser\n",
    "# 2 Pullover\n",
    "# 3 Dress\n",
    "# 4 Coat\n",
    "# 5 Sandal\n",
    "# 6 Shirt\n",
    "# 7 Sneaker\n",
    "# 8 Bag\n",
    "# 9 Ankle boot\n",
    "print(f'Index: {INDEX}')\n",
    "print(f'Label: {y_train[INDEX]}')\n",
    "print(x_train[INDEX])\n",
    "plt.imshow(x_train[INDEX], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Preprocessing\n",
    "# --------------------------------\n",
    "\n",
    "# divide by 255 to normalize\n",
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzalo/.virtualenvs/genv/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# Define Model\n",
    "# --------------------------------\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=tf._optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# sparse_categorical_crossentropy:\n",
    "# 1. labels are integers (not one-hot encoded)\n",
    "# 2. Typical for multiclass classification\n",
    "# 3. Based on cross-entropy. \n",
    "# 4. Como softmax genera probabilidades, cross-entropy calcula, para la probabilidad predicha de la true-label segun trainning-labels\n",
    "#    loss = -log(y_c). Con esto, si la prob. fuera 1, loss = 0. Penaliza bajas probabilidades para la clase verdadera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL TRAINING:\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.6264\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3803\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.3390\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3128\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2969\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2834\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2559\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2432\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2395\n",
      "\n",
      "MODEL EVALUATION:\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8726 - loss: 0.3625\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# Train\n",
    "# --------------------------------\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL EVALUATION:\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8725 - loss: 0.3624\n",
      "LOSS: 0.35786956548690796\n",
      "ACCURACY: 0.8723000288009644\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# EVALUATION\n",
    "# --------------------------------\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "eval_results = model.evaluate(x_test, y_test, return_dict=True)\n",
    "print(f'LOSS: {eval_results[\"loss\"]}')\n",
    "print(f'ACCURACY: {eval_results[\"accuracy\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
